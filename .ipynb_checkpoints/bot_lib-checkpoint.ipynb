{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "82b51e0e-8190-4b02-86be-64665a7f878d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install langchain --quiet\n",
    "%pip install numpy --quiet\n",
    "%pip install boto3 --quiet\n",
    "%pip install PyPDF2 --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "00cf846e-2d8a-4711-a002-c1420582e285",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import boto3\n",
    "from langchain.embeddings import BedrockEmbeddings\n",
    "from langchain.indexes import VectorstoreIndexCreator\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.llms.bedrock import Bedrock\n",
    "from langchain.embeddings import BedrockEmbeddings\n",
    "from numpy import dot\n",
    "from numpy.linalg import norm\n",
    "from PyPDF2 import PdfReader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "2cd08f99-0b79-4ac1-9282-16be296eefcb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Manchester is the largest and most populous city in New Hampshire.\n"
     ]
    }
   ],
   "source": [
    "## testing \n",
    "\n",
    "session = boto3.Session(\n",
    "    profile_name=os.environ.get(\"BWB_PROFILE_NAME\")\n",
    ") #sets the profile name to use for AWS credentials\n",
    "\n",
    "bedrock = session.client(\n",
    "    service_name='bedrock-runtime', #creates a Bedrock client\n",
    "    region_name=os.environ.get(\"BWB_REGION_NAME\"),\n",
    "    endpoint_url=os.environ.get(\"BWB_ENDPOINT_URL\")\n",
    ") \n",
    "bedrock_model_id = \"ai21.j2-ultra-v1\" #set the foundation model\n",
    "\n",
    "prompt = \"What is the largest city in New Hampshire?\" #the prompt to send to the model\n",
    "\n",
    "body = json.dumps({\n",
    "    \"prompt\": prompt, #AI21\n",
    "    \"maxTokens\": 1024, \n",
    "    \"temperature\": 0, \n",
    "    \"topP\": 0.5, \n",
    "    \"stopSequences\": [], \n",
    "    \"countPenalty\": {\"scale\": 0 }, \n",
    "    \"presencePenalty\": {\"scale\": 0 }, \n",
    "    \"frequencyPenalty\": {\"scale\": 0 }\n",
    "}) #build the request payload\n",
    "\n",
    "response = bedrock.invoke_model(body=body, modelId=bedrock_model_id, accept='application/json', contentType='application/json') #send the payload to Bedrock\n",
    "response_body = json.loads(response.get('body').read()) # read the response\n",
    "\n",
    "response_text = response_body.get(\"completions\")[0].get(\"data\").get(\"text\") #extract the text from the JSON response\n",
    "\n",
    "print(response_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "52e5b193-0767-45ea-b421-0c94b30b6a03",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## create LLm\n",
    "def get_llm():\n",
    "    \n",
    "    model_kwargs = { #AI21\n",
    "        \"maxTokens\": 2000, \n",
    "        \"temperature\": 0, \n",
    "        \"topP\": 0.5, \n",
    "        \"stopSequences\": [], \n",
    "        \"countPenalty\": {\"scale\": 0 }, \n",
    "        \"presencePenalty\": {\"scale\": 0 }, \n",
    "        \"frequencyPenalty\": {\"scale\": 0 } \n",
    "    }\n",
    "    \n",
    "    llm = Bedrock(\n",
    "        credentials_profile_name=os.environ.get(\"BWB_PROFILE_NAME\"), #sets the profile name to use for AWS credentials (if not the default)\n",
    "        region_name=os.environ.get(\"BWB_REGION_NAME\"), #sets the region name (if not the default)\n",
    "        endpoint_url=os.environ.get(\"BWB_ENDPOINT_URL\"), #sets the endpoint URL (if necessary)\n",
    "        model_id=\"ai21.j2-ultra-v1\", #set the foundation model\n",
    "        model_kwargs=model_kwargs) #configure the properties for Claude\n",
    "    \n",
    "    return llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "288a1ae3-d7d4-4073-8357-205ae92aac28",
   "metadata": {},
   "outputs": [],
   "source": [
    "## gets looped and each resume path differ by the ending\n",
    "\n",
    "def get_index(file): #creates and returns an in-memory vector store to be used in the application\n",
    "    \n",
    "    embeddings = BedrockEmbeddings(\n",
    "        credentials_profile_name=os.environ.get(\"BWB_PROFILE_NAME\"), #sets the profile name to use for AWS credentials (if not the default)\n",
    "        region_name=os.environ.get(\"BWB_REGION_NAME\"), #sets the region name (if not the default)\n",
    "        endpoint_url=os.environ.get(\"BWB_ENDPOINT_URL\"), #sets the endpoint URL (if necessary)\n",
    "    ) #create a Titan Embeddings client\n",
    "\n",
    "    loader = PdfReader(file) #load the pdf file\n",
    "    \n",
    "    text_splitter = RecursiveCharacterTextSplitter( #create a text splitter\n",
    "        separators=[\"\\n\\n\", \"â€¢\", \".\", \" \"], #split chunks at (1) paragraph, (2) line, (3) sentence, or (4) word, in that order\n",
    "        chunk_size=1000, #divide into 1000-character chunks using the separators above\n",
    "        chunk_overlap=100 #number of characters that can overlap with previous chunk\n",
    "    )\n",
    "    \n",
    "    index_creator = VectorstoreIndexCreator( #create a vector store factory\n",
    "        vectorstore_cls=FAISS, #use an in-memory vector store for demo purposes\n",
    "        embedding=embeddings, #use Titan embeddings\n",
    "        text_splitter=text_splitter, #use the recursive text splitter\n",
    "    )\n",
    "    \n",
    "    index_from_loader = index_creator.from_loaders([loader]) #create an vector store index from the loaded PDF\n",
    "    \n",
    "    return index_from_loader #return the index to be cached by the client app"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "1e46766b-5515-48fb-b04d-0c9d2ed6be46",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rag_response(index, question): #rag client function\n",
    "    \n",
    "    llm = get_llm()\n",
    "    \n",
    "    response_text = index.query(question=question, llm=llm) #search against the in-memory index, stuff results into a prompt and send to the llm\n",
    "    \n",
    "    return response_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "49fc6d5c-4229-43cf-a894-0ae9dce27e7f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## main function\n",
    "\n",
    "belc = BedrockEmbeddings()\n",
    "\n",
    "class EmbedItem:\n",
    "    def __init__(self, text, position):\n",
    "        self.text = text\n",
    "        self.embedding = belc.embed_query(text)\n",
    "        self.position = position\n",
    "\n",
    "class ComparisonResult:\n",
    "    def __init__(self, text, similarity, position):\n",
    "        self.text = text\n",
    "        self.similarity = similarity\n",
    "        self.position = position\n",
    "        \n",
    "def calculate_similarity(a, b): #See Cosine Similarity: https://en.wikipedia.org/wiki/Cosine_similarity\n",
    "    return dot(a, b) / (norm(a) * norm(b))\n",
    "\n",
    "def run(files):\n",
    "    candidates = []\n",
    "    int = 0\n",
    "    for file in files:\n",
    "        input_text = \"Extract the technical skills which is only supported by the experiences listed in the resume, and the language, candidate name, sex, country and education of the resume. And filter out the skills without being supported by experiences.\"\n",
    "        index = get_index(file)\n",
    "        response_content = get_rag_response(index=index, question=input_text)\n",
    "        candidates.append(EmbedItem(response_content, i+1))\n",
    "        i+=1\n",
    "    return candidates\n",
    "\n",
    "def compare(job_description, items):\n",
    "    result = []\n",
    "    e1 = EmbedItem(job_description, 0)\n",
    "    cosine_comparisons = []\n",
    "    for e2 in items:\n",
    "        similarity_score = calculate_similarity(e1.embedding, e2.embedding)\n",
    "        cosine_comparisons.append(ComparisonResult(e2.text, similarity_score, e2.position)) #save the comparisons to a list\n",
    "    cosine_comparisons.sort(key=lambda x: x.similarity, reverse=True) # list the closest matches first\n",
    "    for c in cosine_comparisons:\n",
    "        result.append(\"%.6f\" % c.similarity, \"\\t\", (\"resume\"+c.position))\n",
    "    return result"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
